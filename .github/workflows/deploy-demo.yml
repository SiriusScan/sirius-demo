name: Deploy SiriusScan Demo

on:
  # Scheduled rebuilds (daily at 2 AM UTC)
  schedule:
    - cron: "0 2 * * *"

  # Manual trigger
  workflow_dispatch:
    inputs:
      skip_seeding:
        description: "Skip data seeding step"
        required: false
        default: false
        type: boolean
      force_rebuild:
        description: "Force rebuild even if no changes"
        required: false
        default: false
        type: boolean

  # Trigger from main Sirius repository when code changes
  # This acts as a canary - demo rebuilds on every Sirius main branch update
  repository_dispatch:
    types: [sirius-demo-updated, sirius-main-updated]

  # Trigger on ANY push to main branch (no path filters)
  # This ensures demo rebuilds whenever demo repo code changes
  # Acts as a canary for bad pushes to main
  push:
    branches: [main]

  # Trigger on pull requests to main (for testing infrastructure changes)
  pull_request:
    branches: [main]
    paths:
      - "infra/**"
      - "scripts/**"
      - "data/**"
      - "fixtures/**"
      - ".github/workflows/**"

env:
  AWS_REGION: us-west-2
  TERRAFORM_DIR: infra/demo
  DEMO_INSTANCE_TYPE: t3.medium

jobs:
  deploy:
    name: Deploy Demo Environment
    runs-on: ubuntu-latest
    timeout-minutes: 30

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      - name: Terraform Format Check
        id: fmt
        run: terraform -chdir=${{ env.TERRAFORM_DIR }} fmt -check -recursive
        continue-on-error: true

      - name: Terraform Init
        id: init
        run: terraform -chdir=${{ env.TERRAFORM_DIR }} init

      - name: Terraform Validate
        id: validate
        run: terraform -chdir=${{ env.TERRAFORM_DIR }} validate -no-color

      - name: Terraform Plan
        id: plan
        run: |
          terraform -chdir=${{ env.TERRAFORM_DIR }} plan \
            -var="vpc_id=vpc-416eeb39" \
            -var="subnet_id=subnet-d31ffe8e" \
            -var="aws_region=us-west-2" \
            -var="instance_type=${{ env.DEMO_INSTANCE_TYPE }}" \
            -var="root_volume_size=30" \
            -var='public_key=${{ secrets.DEMO_SSH_PUBLIC_KEY }}' \
            -no-color -out=tfplan
        continue-on-error: true

      - name: Check for changes
        id: changes
        run: |
          if [ -f tfplan ]; then
            if terraform show -no-color tfplan | grep -q "No changes"; then
              echo "changes=false" >> $GITHUB_OUTPUT
            else
              echo "changes=true" >> $GITHUB_OUTPUT
            fi
          else
            echo "changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Skip deployment if no changes
        if: steps.changes.outputs.changes == 'false' && github.event_name != 'workflow_dispatch'
        run: |
          echo "No infrastructure changes detected. Skipping deployment."
          exit 0

      - name: Destroy existing infrastructure
        id: destroy
        run: |
          echo "üóëÔ∏è Destroying existing demo infrastructure..."

          # Use comprehensive cleanup script
          chmod +x scripts/cleanup-aws-resources.sh
          ./scripts/cleanup-aws-resources.sh

          echo "‚úÖ Cleanup completed!"
        continue-on-error: true

      - name: Wait for cleanup
        run: |
          echo "‚è≥ Waiting 30 seconds for AWS cleanup..."
          sleep 30

      - name: Deploy new infrastructure
        id: deploy
        run: |
          echo "üöÄ Deploying new demo infrastructure..."
          terraform -chdir=${{ env.TERRAFORM_DIR }} init
          terraform -chdir=${{ env.TERRAFORM_DIR }} apply \
            -var="vpc_id=vpc-416eeb39" \
            -var="subnet_id=subnet-d31ffe8e" \
            -var="aws_region=us-west-2" \
            -var="instance_type=${{ env.DEMO_INSTANCE_TYPE }}" \
            -var="root_volume_size=30" \
            -var='public_key=${{ secrets.DEMO_SSH_PUBLIC_KEY }}' \
            -auto-approve

          # Get instance details
          INSTANCE_ID=$(terraform -chdir=${{ env.TERRAFORM_DIR }} output -raw instance_id)
          PUBLIC_IP=$(terraform -chdir=${{ env.TERRAFORM_DIR }} output -raw instance_public_ip)

          echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT
          echo "public_ip=$PUBLIC_IP" >> $GITHUB_OUTPUT
          echo "ui_url=http://$PUBLIC_IP:3000" >> $GITHUB_OUTPUT
          echo "api_url=http://$PUBLIC_IP:9001" >> $GITHUB_OUTPUT

      - name: Wait for instance to be ready
        run: |
          echo "‚è≥ Waiting for instance to be ready..."
          sleep 60

      - name: Collect diagnostics before health check
        if: always()
        run: |
          echo "üìä Collecting system diagnostics..."
          PUBLIC_IP="${{ steps.deploy.outputs.public_ip }}"
          INSTANCE_ID="${{ steps.deploy.outputs.instance_id }}"
          
          # Try to get bootstrap logs via SSM if possible
          echo "Attempting to retrieve bootstrap logs..."
          aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=["tail -200 /var/log/sirius-bootstrap.log"]' \
            --region us-west-2 \
            --output text \
            --query "Command.CommandId" > /tmp/command-id.txt 2>&1 || echo "SSM command failed, will check logs later"
          
          # Wait a moment for command to execute
          sleep 5
          
          # Try to get command output
          if [ -f /tmp/command-id.txt ] && [ -s /tmp/command-id.txt ]; then
            COMMAND_ID=$(cat /tmp/command-id.txt | head -1)
            if [ -n "$COMMAND_ID" ] && [ "$COMMAND_ID" != "None" ]; then
              echo "Retrieving command output..."
              aws ssm get-command-invocation \
                --command-id "$COMMAND_ID" \
                --instance-id "$INSTANCE_ID" \
                --region us-west-2 \
                --query "StandardOutputContent" \
                --output text 2>&1 | head -100 || echo "Could not retrieve SSM output"
            fi
          fi
          
          echo "Diagnostics collection complete"

      - name: Health check
        id: health
        run: |
          echo "üîç Performing health checks..."
          PUBLIC_IP="${{ steps.deploy.outputs.public_ip }}"
          INSTANCE_ID="${{ steps.deploy.outputs.instance_id }}"

          # Wait for API to be ready (up to 20 minutes with longer intervals)
          for i in {1..60}; do
            if curl -f -s http://$PUBLIC_IP:9001/health > /dev/null; then
              echo "‚úÖ API is healthy"
              break
            fi
            echo "‚è≥ Waiting for API... (attempt $i/60)"
            
            # Every 10 attempts, try to get some diagnostics
            if [ $((i % 10)) -eq 0 ]; then
              echo "üìä Checking system status (attempt $i)..."
              # Try to get Docker logs via SSM
              aws ssm send-command \
                --instance-ids "$INSTANCE_ID" \
                --document-name "AWS-RunShellScript" \
                --parameters 'commands=["cd /opt/sirius/repo && docker compose ps -a && docker compose logs --tail=30"]' \
                --region us-west-2 \
                --output text \
                --query "Command.CommandId" > /tmp/docker-command-id.txt 2>&1 || true
            fi
            sleep 20
          done

          # Final API check
          if ! curl -f -s http://$PUBLIC_IP:9001/health > /dev/null; then
            echo "‚ùå API health check failed after 20 minutes"
            echo "Checking API logs for debugging..."
            curl -v http://$PUBLIC_IP:9001/health || true
            
            # Try to get comprehensive diagnostics
            echo ""
            echo "üìä Attempting to retrieve comprehensive diagnostics..."
            INSTANCE_ID="${{ steps.deploy.outputs.instance_id }}"
            
            # Get Docker status and logs
            aws ssm send-command \
              --instance-ids "$INSTANCE_ID" \
              --document-name "AWS-RunShellScript" \
              --parameters 'commands=["cd /opt/sirius/repo && echo \"=== Container Status ===\" && docker compose ps -a && echo \"\" && echo \"=== API Logs ===\" && docker compose logs sirius-api --tail=100 && echo \"\" && echo \"=== All Logs ===\" && docker compose logs --tail=50"]' \
              --region us-west-2 \
              --output text \
              --query "Command.CommandId" > /tmp/final-command-id.txt 2>&1 || true
            
            sleep 10
            
            if [ -f /tmp/final-command-id.txt ] && [ -s /tmp/final-command-id.txt ]; then
              FINAL_CMD_ID=$(cat /tmp/final-command-id.txt | head -1)
              if [ -n "$FINAL_CMD_ID" ] && [ "$FINAL_CMD_ID" != "None" ]; then
                echo "Retrieving final diagnostics..."
                aws ssm get-command-invocation \
                  --command-id "$FINAL_CMD_ID" \
                  --instance-id "$INSTANCE_ID" \
                  --region us-west-2 \
                  --query "StandardOutputContent" \
                  --output text 2>&1 | head -200 || echo "Could not retrieve diagnostics"
              fi
            fi
            
            exit 1
          fi

          # Check UI
          if curl -f -s -I http://$PUBLIC_IP:3000 > /dev/null; then
            echo "‚úÖ UI is healthy"
          else
            echo "‚ùå UI health check failed"
            exit 1
          fi

      - name: Update DNS
        if: steps.health.outcome == 'success'
        run: |
          echo "üåê Updating DNS record for sirius.opensecurity.com..."
          ELASTIC_IP="${{ steps.deploy.outputs.elastic_ip }}"
          DOMAIN="opensecurity.com"
          SUBDOMAIN="sirius"

          # Run DNS update script
          chmod +x scripts/update-dns.sh
          ./scripts/update-dns.sh $ELASTIC_IP $DOMAIN $SUBDOMAIN || echo "‚ö†Ô∏è DNS update failed, but deployment continues"

      - name: Seed demo data
        if: github.event.inputs.skip_seeding != 'true' && steps.health.outcome == 'success'
        run: |
          echo "üå± Seeding demo data..."
          PUBLIC_IP="${{ steps.deploy.outputs.public_ip }}"

          # Wait a bit more for services to be fully ready
          sleep 30

          # Run seeding script
          chmod +x scripts/seed_demo.sh
          ./scripts/seed_demo.sh $PUBLIC_IP || echo "‚ö†Ô∏è Data seeding failed, but deployment continues"

      - name: Generate deployment summary
        id: summary
        run: |
          echo "üìä Generating deployment summary..."

          PUBLIC_IP="${{ steps.deploy.outputs.public_ip }}"
          INSTANCE_ID="${{ steps.deploy.outputs.instance_id }}"

          cat << EOF > deployment-summary.md
          # SiriusScan Demo Deployment Summary

          **Deployment Time**: $(date -u)
          **Trigger**: ${{ github.event_name }}
          **Commit**: ${{ github.sha }}
          **Branch**: ${{ github.ref_name }}

          ## Instance Details
          - **Instance ID**: \`$INSTANCE_ID\`
          - **Public IP**: \`$PUBLIC_IP\`
          - **Instance Type**: ${{ env.DEMO_INSTANCE_TYPE }}
          - **Region**: ${{ env.AWS_REGION }}

          ## Access URLs
          - **UI**: http://$PUBLIC_IP:3000
          - **API**: http://$PUBLIC_IP:9001
          - **Health Check**: http://$PUBLIC_IP:9001/health

          ## Domain Access (Static IP)
          - **UI**: http://sirius.opensecurity.com:3000
          - **API**: http://sirius.opensecurity.com:9001
          - **Elastic IP**: ${{ steps.deploy.outputs.elastic_ip }}

          ## SSM Access
          \`\`\`bash
          aws ssm start-session --target $INSTANCE_ID --region ${{ env.AWS_REGION }}
          \`\`\`

          ## Status
          - **Infrastructure**: ‚úÖ Deployed
          - **API Health**: ‚úÖ Responding
          - **UI Health**: ‚úÖ Responding
          - **Data Seeding**: ${{ github.event.inputs.skip_seeding == 'true' && '‚è≠Ô∏è Skipped' || '‚úÖ Completed' }}

          ## Next Steps
          1. Test the demo at the URLs above
          2. Verify all services are working correctly
          3. Check logs if any issues are found

          ---
          *This deployment was created automatically by GitHub Actions*
          EOF

      - name: Upload deployment summary
        uses: actions/upload-artifact@v4
        with:
          name: deployment-summary
          path: deployment-summary.md

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('deployment-summary.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

      - name: Deployment success notification
        if: success()
        run: |
          echo "üéâ SiriusScan Demo deployment completed successfully!"
          echo "UI: ${{ steps.deploy.outputs.ui_url }}"
          echo "API: ${{ steps.deploy.outputs.api_url }}"

      - name: Deployment failure notification
        if: failure()
        run: |
          echo "‚ùå SiriusScan Demo deployment failed!"
          echo "Check the logs above for details."
          echo "Instance ID: ${{ steps.deploy.outputs.instance_id || 'N/A' }}"
